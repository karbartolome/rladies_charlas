---
title: "R-Ladies - El uso de m√∫ltiples lenguajes en Rmarkdown"
subtitle: "‚öî<br/>with xaringan"
author: "Karina Bartolom√©"
output:
  xaringan::moon_reader:
    css: ["default", "rladies", "rladies-fonts"]
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      navigation: 
        scroll: false
    includes:
      in_header: header.html
      after_body: "collapseoutput.js"
---
background-position: 50% 50%
class: center, inverse

<img src="images/multilingual.png" width="500px" height="500px" style="position:center;">
 
# M√∫ltiples idiomas

---

background-position: 50% 50%
class: center, inverse

<img src="images/multilingual_code.png" width="500px" height="500px" style="position:center;">
 
#  M√∫ltiples lenguajes

---

# El uso de diversos lenguajes en rmarkdown

```{r include=FALSE}
knitr::opts_chunk$set(comment = NA)

options(scipen=999)
options(reticulate.repl.quiet = TRUE)
```

```{r xaringan-panelset, echo=FALSE}
xaringanExtra::use_panelset()
```

```{css, echo=F}
    /* Table width = 100% max-width */

    .remark-slide table{
        width: 100%;
    }

    /* Change the background color to white for shaded rows (even rows) */

    .remark-slide thead, .remark-slide tr:nth-child(2n) {
        background-color: white;
    }
```


Para trabajar con distintos lenguajes en Rmarkdown, se utilizan **chunks** que referencien al lenguaje que se quiere utilizar: 

````
```{r}`r ''`
# Ac√° se escribe c√≥digo R
```
````

````
```{python}`r ''`
# Ac√° se escribe c√≥digo Python
```
````

````
```{julia}`r ''`
# Ac√° se escribe c√≥digo Python
```
````

````
```{sql}`r ''`
# Ac√° se escribe sql
```
````

Etc.

---

# R en Rmarkdown

üîπ En **Rmarkdown**, se utiliza un chunk R para cargar las librer√≠as R:

```{r Librer√≠as R, message=FALSE, warning=FALSE}
library(reticulate) # Para Python
library(tidyverse)  
library(gt) # Para tablas
```

---
```{r example-plot}

ggplot(iris) +
  aes(x = Sepal.Length) +
  geom_histogram(   #<<
    binwidth = 0.25 #<<
  )                 #<<
```

---
```{r, eval=FALSE}

{{ iris %>% }}
  {{ ggplot() + }}
  aes(x = {{ Sepal.Length }} ) + 
  geom_histogram(binwidth = 0.25) 
          
```

---

# Python en Rmarkdown

1.   Definir un `conda environment` a utilizar. 

En este caso, se cre√≥ un environment espec√≠fico para este proyecto. 

```{r, eval=FALSE}
reticulate::conda_create(envname='rladies', 
                         python_version="3.8.8")
```

-   Desde Anaconda, en la solapa de **Environments**, se selecciona el environment creado y se abre la terminal. Desde ah√≠, se activa con: `conda activate rladies`

Luego de finalizar el proyecto es posible eliminar este environment desde Anaconda para liberar espacio, ya que los paquetes se ir√°n instalando en ese environment. 

---

# Python en Rmarkdown

2. Se instalan los paquetes a utilizar. En este caso, lo hice desde la terminal del environment desde Anaconda:

    -   [x] ‚ûï **numpy**: conda install numpy

    -   [x] üêº **pandas**: conda install pandas 
    
    -   [x] üìä **seaborn**: conda install seaborn
    
    -   [x] **statsmodels**: conda install -c anaconda statsmodels


3. Se define que el environment a utilizar es el que ha sido creado:

```{r}
reticulate::use_condaenv(condaenv = 'rladies', 
                         required = TRUE)
```


---

üîπSe utiliza un chunk python para cargar las librer√≠as de python:

```{python Librer√≠as python}
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
```


```{python opciones_python}
sns.set_theme(style="ticks", palette="pastel")

pd.set_option('display.max_columns', 10)
pd.set_option('display.max_colwidth', 20)

pd.set_option('display.float_format', lambda x: '%.2f' % x)
```




---

class: inverse, center, middle

# 0. Datos

---

Aclaraci√≥n!


- Los datos para esta presentaci√≥n provienen del paquete {opentradestatistics}

- Los ejemplos pueden no tener sentido real (agrupaciones de ramas de actividades que podr√≠an no tener relaci√≥n, etc.). El objetivo es utilizar datos reales para mostrar diferentes funcionalidades, no el an√°lisis de los datos en s√≠. 

- Sin embargo, siempre me parece interesante usar datos reales para motivar a quienes quieran utilizarlos luego. 



---

# Lectura de datos con R

üîπ Datos de Tidytuesday: Vignettes de paquetes en CRAN

```{r data_1, message=FALSE, echo=FALSE, eval=FALSE}
df_cran <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-03-15/cran.csv')

df_task_views <- readr::read_csv('https://raw.githubusercontent.com/karbartolome/cran-packages/main/01_data/df_task_views.csv')
```


```{r data_comercio, message=FALSE, warning=FALSE}
df_comercio  <- readr::read_csv('data/df_arg_mx.csv')
 
df_secciones <- readr::read_csv('data/df_secciones.csv')

df_commodities <- readr::read_csv('data/df_commodities.csv')
```

# Lectura de datos con python

```{python, echo=FALSE, eval=FALSE}
import os
os.chdir(f'{os.getcwd()}/02_slides')
```

```{python data_1_python, message=FALSE}
df_comercio_pd = pd.read_csv('data/df_arg_mx.csv')
```

---

```{r}
df_comercio %>% head(2)
```

‚ö° Objetos cross lenguaje  R -> Python ‚ö° 

```{python}
r.df_comercio.head(2)
```

---

Se crea una lista de variables relevantes en un chunk python: 

```{python}
variables = ['year','commodity_code','trade_value_usd_exp']
```

-------------------------------------------

üîπ Dos chunks que generan el mismo output: 

.panelset[

.panel[.panel-name[R con objeto Python]

````
```{r}`r ''`
py$df_comercio_pd %>% 
  select(all_of(py$variables)) %>% 
  head(2)
```
````

```{r, echo=FALSE}
py$df_comercio_pd %>% 
  select(all_of(py$variables)) %>% 
  head(2)
```

]

.panel[.panel-name[Python con objeto R]

````
```{python}`r ''`
(r.df_comercio
  .filter(variables)
  .head(2))
```
````

```{python, echo=FALSE}
(r.df_comercio
  .filter(variables, axis=1)
  .head(2))
```

]



]



---

class: inverse, center, middle

# 1. Estad√≠stica descriptiva

---
.panelset[
.panel[.panel-name[R summary]

```{r summary}
df_comercio %>% summary()
```

]

.panel[.panel-name[Python .describe()]

Variables que no son object: 

```{python describe}
r.df_comercio.describe(exclude='object')
```

Variables tipo object: 

```{python describe_obj}
r.df_comercio.describe(include='object')
```

]


.panel[.panel-name[R skim(df)]

```{r skimr_gt}
py$df_comercio_pd %>% 
  select(where(is.numeric)) %>% 
  skimr::skim() %>% 
  select(-skim_type, -complete_rate) %>% 
  gt() %>% 
  tab_header(title=md('**Comercio exterior**: Argentina y M√©xico'), 
             subtitle='Estad√≠stica descriptiva') %>% 
  opt_align_table_header('left') %>% 
  fmt_number(columns=3:4) 
```

]

]


---

Las semillas no funcionan igual en r y python, sirven para reproducibilidad dentro de un lenguaje pero al pasar al otro var√¨an los resultados. 


```{r}
set.seed(42)
df_comercio %>% 
  sample_n(2) %>% 
  select(commodity_code, year)
```


```{python}
(r.df_comercio
  .sample(2, random_state=42)
  [['commodity_code', 'year']]
)
```




---

class: inverse, center, middle

# 2. Uni√≥n de dataframes

---
.panelset[
.panel[.panel-name[R]

```{r}
df <- df_comercio %>% 
  
  # Left join con datos de commodities
  left_join(df_commodities %>% 
              select(commodity_code, 
                     commodity_fullname_english, 
                     group_fullname_english), 
            by='commodity_code') %>% 
  
  # Left join con secciones
  left_join(df_secciones) %>%
  
  # Selecci√≥n de variables y renombrarlas
  select(
    a√±o             = year,
    pais            = reporter,
    socio           = partner, 
    commodity       = commodity_fullname_english,
    grupo           = group_fullname_english,
    seccion         = section_shortname_english, 
    expo            = trade_value_usd_exp,
    impo            = trade_value_usd_imp
  )
```

]

.panel[.panel-name[Python]
```{python}
df_py = (r.df_comercio

  # Left join con datos de commodities
  .merge(r.df_commodities[['commodity_code', 
                           'commodity_fullname_english', 
                           'group_fullname_english']], 
         on='commodity_code')
         
  # Left join con secciones
  .merge(r.df_secciones, on='section_code')
  
  # Renombrar variables
  .rename({
    'year'                       : 'a√±o',
    'reporter'                   : 'pais',
    'partner'                    : 'socio',
    'commodity_fullname_english' : 'commodity',
    'group_fullname_english'     : 'grupo',
    'section_shortname_english'  : 'seccion',
    'trade_value_usd_exp'        : 'expo',
    'trade_value_usd_imp'        : 'impo'
  }, axis=1)
  
  # Selecci√≥n de las columnas relevantes (mismas que df anterior en r)
  [r.df.columns]
  
  # √çndices que queden bien
  .reset_index(drop=True)
)
```

]


.panel[.panel-name[Dataframes generados]

üîπ R dataframe:

```{r}
df %>% head(1) %>% gt::gt()
```

üîπ Pandas dataframe: 

```{r}
py$df_py %>% head(1) %>% gt::gt()
```

]

.panel[.panel-name[Comparaci√≥n]

Se utiliza el paquete waldo para comparar los filtros generados:

```{r}
waldo::compare(data.frame(df),
               data.frame(py$df_py))
```

]

]

---

class: inverse, center, middle

# 3. Filtros

---
.panelset[
.panel[.panel-name[R]

```{r}
filtro_r <- df %>% 
  
  filter(
    
    # Condici√≥n simple (equivalencia)
    a√±o == 2019 &
      
    # Condici√≥n OR con funci√≥n quantile()
    (expo   > quantile(df$expo,0.6) | 
     impo   > quantile(df$impo,0.6) ) &
    
    # Filtro por expresi√≥n regular
    str_detect(tolower(commodity), 'metal')
  )
```

]

.panel[.panel-name[Python]

```{python}
filtro_py = (r.df

  .query("""
         a√±o == 2019 and                              \
                                                      \
         (expo   > expo.quantile(0.6) or              \
          impo   > impo.quantile(0.6)) and            \
                                                      \
         commodity.str.lower().str.contains('metal')
        """, 
        engine='python') 
        
  .reset_index(drop=True)
)
```
]

.panel[.panel-name[Dataframes generados]

üîπ R dataframe:

```{r}
filtro_r %>% head(1) %>% gt::gt()
```

üîπ Pandas dataframe: 

```{r}
py$filtro_py %>% head(1) %>% gt::gt()
```

]


.panel[.panel-name[Comparaci√≥n]

Se utiliza el paquete waldo para comparar los filtros generados:

```{r}
waldo::compare(data.frame(filtro_r),
               data.frame(py$filtro_py))
```
]

]









---

class: inverse, center, middle

# 3. Nuevas columnas

---


.panelset[
.panel[.panel-name[R]

```{r}
columnas_r <- df %>% 
  
  mutate(
    
    # C√°lculo
    expo_netas = expo - impo,
    
    # If else
    d_2020 = ifelse(a√±o==2020,1,0),
    
    # Case when
    categoria_extra = case_when(
      
      str_detect(commodity,'metal|machines') ~ 'Metal & maquinarias',
      str_detect(commodity,'animal|food|vegetable') ~ 'Cultivos y animales',
      TRUE ~ 'Otros'
      
    )
  )
```

]

.panel[.panel-name[Python]
```{python}
columnas_py = (r.df
  .assign(
    
    # C√°lculo
    expo_netas      = lambda x: x['expo'] - x['impo'],
    
    # If else
    d_2020          = lambda x: np.where(x['a√±o']==2020,1,0),
     
    # Case when
    categoria_extra = lambda x: np.select(
      
      [x['commodity'].str.contains('metal|machines'),
       x['commodity'].str.contains('animal|food|vegetable')],
      
      ['Metal & maquinarias',
       'Cultivos y animales'],
    
      default = 'Otros'
    )
    
  )
)
```

]

.panel[.panel-name[Dataframes generados]

üîπ R dataframe:

```{r}
columnas_r %>% head(1) %>% gt::gt()
```

üîπ Pandas dataframe: 

```{r}
py$columnas_py %>% head(1) %>% gt::gt()
```

]



.panel[.panel-name[Comparaci√≥n]
```{r}
waldo::compare(data.frame(columnas_r),
               data.frame(py$columnas_py))
```

]

]









---

class: inverse, center, middle

# 5. Agregaci√≥n

---

```{r}

```


---

class: inverse, center, middle

# 6. Formato wide a long / long a wide (pivot)

---

# Pivot wider

.panelset[
.panel[.panel-name[R]

```{r}
wider_r <- df %>% 
  
  group_by(seccion, a√±o) %>% 
  
  summarise(expo = sum(expo), .groups = 'keep') %>% 
  
  ungroup() %>% 
  
  pivot_wider(names_from=a√±o, 
              names_prefix='y_',
              values_from=expo) %>% 
  
  arrange(desc(y_2020, y_2019, y_2018, y_2017))
```

]

.panel[.panel-name[Python]
```{python}
wider_py = (r.df

 .assign(a√±o=lambda x: ['y_'+str(int(i)) for i in x['a√±o']])
 
 .groupby(['seccion','a√±o'], as_index=False)
 
 .agg(expo = ('expo','sum'))
 
 .pivot(index='seccion', 
        columns='a√±o',
        values='expo')
  
  .sort_values(['y_2020', 'y_2019', 'y_2018', 'y_2017'], 
               ascending=False)
  
  .reset_index(drop=False)

)

```
]

.panel[.panel-name[Dataframes generados]

üîπ R dataframe:

```{r}
wider_r %>% head(2) %>% gt::gt()
```

üîπ Pandas dataframe: 

```{r}
py$wider_py %>% head(2) %>% gt::gt()
```

]



.panel[.panel-name[Comparaci√≥n]
```{r}
waldo::compare(data.frame(wider_r),
               data.frame(py$wider_py))
```

]

]


---

# Pivot longer

.panelset[
.panel[.panel-name[R]

```{r}
longer_r <- wider_r %>% 
  
  pivot_longer(-seccion, names_to='a√±o', values_to='expo') %>% 
  
  mutate(a√±o=str_replace(a√±o, 'y_','')) %>% 
  
  arrange(seccion, a√±o)
```

]

.panel[.panel-name[Python]
```{python}
longer_py = (wider_py

  .melt(id_vars='seccion', value_vars=['y_2017','y_2018','y_2019','y_2020'], 
        value_name='expo')
  
  .assign(a√±o = lambda x: [i.replace('y_','') for i in x['a√±o']], 
          temp_var = lambda x: [i.lower().replace(' ','') for i in x['seccion']])
  
  .sort_values(['temp_var','a√±o'])
  
  .drop('temp_var',axis=1)
  
  .reset_index(drop=True)

)
```
]

.panel[.panel-name[Dataframes generados]

üîπ R dataframe:

```{r}
longer_r %>% head(2) %>% gt::gt()
```

üîπ Pandas dataframe: 

```{r}
py$longer_py %>% head(2) %>% gt::gt()
```

]



.panel[.panel-name[Comparaci√≥n]
```{r}
waldo::compare(data.frame(longer_r),
               data.frame(py$longer_py))
```

]

]


---

class: inverse, center, middle

# 7. Visualizaci√≥n

---

Se definen las secciones relevantes: 

```{r}
secciones_relevantes <- longer_r %>% 
  group_by(seccion) %>% 
  summarise(expo_4y=sum(expo)) %>% 
  ungroup() %>% 
  arrange(desc(expo_4y)) %>% 
  top_n(5) %>% pull(seccion)
```


---

.panelset[
.panel[.panel-name[R]

Reordenando las secciones por el promedio de las exportaciones:

```{r, fig.height=5, fig.width=10}
longer_r %>% 
  filter(seccion %in% secciones_relevantes) %>% 
  ggplot(aes(x=expo, y=reorder(seccion, expo)))+
    geom_boxplot()
```

]

.panel[.panel-name[Python]

.details[
```{python, out.width='50%', fig.align='center', code_folding=TRUE}
temp = longer_py[longer_py['seccion'].isin(r.secciones_relevantes)]

orden = (temp.groupby('seccion', as_index=False).expo.mean()
  .sort_values('expo', ascending=False)['seccion'])
```
]



```{python, out.width='50%', fig.align='center', out.height='50%', fig.width=10, fig.height=5}
sns.boxplot(x="expo", y="seccion", data=temp, order = orden)
```
]

]

---


Data on Y (Personal Consumption Expenditure) and X (Gross Domestic Product, 1960‚Äì2005),
both in 2000 Billions of Dollars

```{r}
pers_con = data.frame (
  year = c(1960:2005),
  epc = c(1597.4, 1630.3, 1711.1, 1781.6, 1888.4,
             2007.7, 2121.8, 2185.0, 2310.5, 2396.4,
              2451.9, 2545.5, 2701.3, 2833.8, 2812.3,
             2876.9, 3035.5, 3164.1, 3303.1, 3383.4,
              3374.1, 3422.2, 3470.3, 3668.6, 3863.3,
             4064.0, 4228.9, 4369.8, 4546.9, 4675.0,
              4770.3, 4778.4, 4934.8, 5099.8, 5290.7,
             5433.5, 5619.4, 5831.8, 6125.8, 6438.6,
              6739.4, 6910.4, 7099.3, 7259.3, 7577.1,
             7841.2),
  gdp = c(2501.8, 2560.0, 2715.2, 2834.0, 2998.6,
              3191.1, 3399.1, 3484.6, 3652.7, 3765.4,
               3771.9, 3898.6, 4105.0, 4341.5, 4319.6,
              4311.2, 4540.9, 4750.5, 5015.0, 5173.4,
               5161.7, 5291.7, 5189.3, 5423.8, 5813.6,
              6053.7, 6263.6, 6475.1, 6742.7, 6981.4,
               7112.5, 7100.5, 7336.6, 7532.7, 7835.5,
              8031.7, 8328.9, 8703.5, 9066.9, 9470.3,
               9817.0, 9890.7, 10048.8, 10301.0, 10703.5,
              11048.6))
```

---

```{python}
import statsmodels.formula.api as smf

reg = smf.ols ("epc ~ gdp", r.pers_con).fit()

modelo = reg.summary2()
```

.panelset[
.panel[.panel-name[Tabla 1]

```{python}
modelo.tables[0]
```
]

.panel[.panel-name[Tabla 2]

```{python}
modelo.tables[1]
```
]

.panel[.panel-name[Tabla 3]

```{python}
modelo.tables[2]
```
]

]



---

```{r}
py$modelo$tables[[1]] %>% gt() %>% 
  
  #fmt_number(everything(),decimals = 2) %>% 
  
  tab_header(title=md('**Tabla 1:** Modelo OLS'),
             
             subtitle = 'Statsmodels (python) a R') %>% 
  
  opt_align_table_header('left')
```

---

```{r}
py$modelo$tables[[2]] %>% gt() %>% 
  
  fmt_number(everything(),decimals = 2) %>% 
  
  tab_header(title=md('**Tabla 2:** Modelo OLS'),
             
             subtitle = 'Statsmodels (python) a R') %>% 
  
  opt_align_table_header('left')
```



---

```{r}
knitr::knit_exit()
```









```{python}
import numpy as np

import statsmodels.api as sm

wider_py['y_2020'] = np.where(wider_py['y_2020'].isna(), 0, wider_py['y_2020'])
X = wider_py[['y_2017','y_2018','y_2019']]
y = wider_py[['y_2020']]

X = sm.add_constant(X, prepend=False)

mod = sm.OLS(y, X)

res = mod.fit()

modelo = (res.summary2().tables[1])
coef_table = modelo.reset_index()

```

```{r}
py$coef_table %>% gt::gt()
```

```{python}
from sklearn.linear_model import LinearRegression
wider_py['y_2020'] = np.where(wider_py['y_2020'].isna(), 0, wider_py['y_2020'])
X = wider_py[['y_2017','y_2018','y_2019']]
y = wider_py[['y_2020']]

modelo = LinearRegression()
modelo.fit(X, y)

modelo.coef_

```


```{r}
wider_r <- df %>% select(commodity, a√±o, expo, impo) %>% 
  
  pivot_wider(names_from=a√±o, 
              values_from=c(expo,impo)) %>% 
  
  mutate(expo_netas_2020 = expo_2020-impo_2020) %>% 
  
  mutate(expo_netas_2020_pos = ifelse(expo_netas_2020 >0,1,0),
         expo_netas_2020_pos = ifelse(is.na(expo_netas_2020_pos),0,expo_netas_2020_pos))
```

```{python}
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression

X = r.wider_r[['expo_2019','impo_2019']]
y = r.wider_r['expo_netas_2020_pos']

pipe = Pipeline([
  ('imputador', SimpleImputer(strategy='constant',fill_value= 0)),
  ('scaler', StandardScaler()), 
  ('reg_logistica',  LogisticRegression())
])
  
pipe.fit(X, y)
modelo = pipe['reg_logistica']
modelo.predict_proba(r.wider_r[['expo_2019','impo_2019']])
```

```{r}
py$modelo$predict_proba(wider_r %>% select(expo_2019, impo_2019))
```



---

# Links utiles

https://www.mit.edu/~amidi/teaching/data-science-tools/conversion-guide/r-python-data-manipulation/#

---

class: inverse, center, middle

# Contacto

<a href="https://karbartolome-blog.netlify.com"><i class="fa fa-link fa-fw"></i>&nbsp; karbartolome-blog.netlify.com</a><br>
<a href="http://twitter.com/karbartolome"><i class="fa fa-twitter fa-fw"></i>&nbsp; @karbartolome</a><br>
<a href="http://github.com/karbartolome"><i class="fa fa-github fa-fw"></i>&nbsp; @karbartolome</a><br>

---


class: center, middle

# Muchas gracias!!

Las slides fueron creadas con el paquete [**xaringan**](https://github.com/yihui/xaringan), utilizando el template de Rladies
















